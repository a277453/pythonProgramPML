{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47c834fa-b3e6-4c8f-9f9a-7c579116155d",
   "metadata": {},
   "source": [
    "# Exercise 1 - Now, using the LinearRegression (sklearn) function of Python\n",
    "# create a regression model and calculate metrics like R2, MAE,\n",
    "# RMSE and analyze the results\n",
    "# Further, use the OLS function from 'statsmodels' package to\n",
    "# perform regression, print the results and review them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d22dee3-edc9-4868-947d-53f8bb1fddf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "265fac0c-21a8-42c5-b882-e979531c7df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got Data \n",
      "           y         x\n",
      "0  7.238462  0.025641\n",
      "1  6.310256  0.051282\n",
      "2  8.315385  0.076923\n",
      "3  4.787179  0.102564\n",
      "4  5.592308  0.128205\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the data from a CSV file\n",
    "try:\n",
    "    df = pd.read_csv('..\\\\data2\\\\data-set-for-SLR-2025.csv')  # Replace 'your_data.csv' with your actual file name\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'your_data.csv' not found. Please ensure the file exists in the correct directory.\")\n",
    "    exit()\n",
    "\n",
    "print (\"Got Data \\n\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d92a16ef-b1ae-4072-b8ed-5862be3894d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025641026   7.238461538\n"
     ]
    }
   ],
   "source": [
    "print(df['x'][0], ' ', df['y'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0709118-fa3d-43ef-89e7-6e710d1f961a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared (R2): 0.8525\n",
      "Mean Absolute Error (MAE): 1.5754\n",
      "Root Mean Squared Error (RMSE): 1.8518\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'feature_column' is your independent variable and 'target_column' is your dependent variable\n",
    "# Adjust these column names based on your CSV file\n",
    "X = df[['x']]  # Features (independent variables)\n",
    "y = df['y']   # Target variable (dependent variable)\n",
    "\n",
    "# 2. Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Create and train the Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 5. Calculate evaluation metrics\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"R-squared (R2): {r2:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "989f3432-45fe-4cd2-a17d-ca927ddfd015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "553f2b98-0c32-4069-903f-9b12c3f1f4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class PolynomialFeatures in module sklearn.preprocessing._polynomial:\n",
      "\n",
      "class PolynomialFeatures(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      " |  PolynomialFeatures(\n",
      " |      degree=2,\n",
      " |      *,\n",
      " |      interaction_only=False,\n",
      " |      include_bias=True,\n",
      " |      order='C'\n",
      " |  )\n",
      " |\n",
      " |  Generate polynomial and interaction features.\n",
      " |\n",
      " |  Generate a new feature matrix consisting of all polynomial combinations\n",
      " |  of the features with degree less than or equal to the specified degree.\n",
      " |  For example, if an input sample is two dimensional and of the form\n",
      " |  [a, b], the degree-2 polynomial features are [1, a, b, a^2, ab, b^2].\n",
      " |\n",
      " |  Read more in the :ref:`User Guide <polynomial_features>`.\n",
      " |\n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  degree : int or tuple (min_degree, max_degree), default=2\n",
      " |      If a single int is given, it specifies the maximal degree of the\n",
      " |      polynomial features. If a tuple `(min_degree, max_degree)` is passed,\n",
      " |      then `min_degree` is the minimum and `max_degree` is the maximum\n",
      " |      polynomial degree of the generated features. Note that `min_degree=0`\n",
      " |      and `min_degree=1` are equivalent as outputting the degree zero term is\n",
      " |      determined by `include_bias`.\n",
      " |\n",
      " |  interaction_only : bool, default=False\n",
      " |      If `True`, only interaction features are produced: features that are\n",
      " |      products of at most `degree` *distinct* input features, i.e. terms with\n",
      " |      power of 2 or higher of the same input feature are excluded:\n",
      " |\n",
      " |      - included: `x[0]`, `x[1]`, `x[0] * x[1]`, etc.\n",
      " |      - excluded: `x[0] ** 2`, `x[0] ** 2 * x[1]`, etc.\n",
      " |\n",
      " |  include_bias : bool, default=True\n",
      " |      If `True` (default), then include a bias column, the feature in which\n",
      " |      all polynomial powers are zero (i.e. a column of ones - acts as an\n",
      " |      intercept term in a linear model).\n",
      " |\n",
      " |  order : {'C', 'F'}, default='C'\n",
      " |      Order of output array in the dense case. `'F'` order is faster to\n",
      " |      compute, but may slow down subsequent estimators.\n",
      " |\n",
      " |      .. versionadded:: 0.21\n",
      " |\n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  powers_ : ndarray of shape (`n_output_features_`, `n_features_in_`)\n",
      " |      `powers_[i, j]` is the exponent of the jth input in the ith output.\n",
      " |\n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |\n",
      " |      .. versionadded:: 0.24\n",
      " |\n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |\n",
      " |      .. versionadded:: 1.0\n",
      " |\n",
      " |  n_output_features_ : int\n",
      " |      The total number of polynomial output features. The number of output\n",
      " |      features is computed by iterating over all suitably sized combinations\n",
      " |      of input features.\n",
      " |\n",
      " |  See Also\n",
      " |  --------\n",
      " |  SplineTransformer : Transformer that generates univariate B-spline bases\n",
      " |      for features.\n",
      " |\n",
      " |  Notes\n",
      " |  -----\n",
      " |  Be aware that the number of features in the output array scales\n",
      " |  polynomially in the number of features of the input array, and\n",
      " |  exponentially in the degree. High degrees can cause overfitting.\n",
      " |\n",
      " |  See :ref:`examples/linear_model/plot_polynomial_interpolation.py\n",
      " |  <sphx_glr_auto_examples_linear_model_plot_polynomial_interpolation.py>`\n",
      " |\n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.preprocessing import PolynomialFeatures\n",
      " |  >>> X = np.arange(6).reshape(3, 2)\n",
      " |  >>> X\n",
      " |  array([[0, 1],\n",
      " |         [2, 3],\n",
      " |         [4, 5]])\n",
      " |  >>> poly = PolynomialFeatures(2)\n",
      " |  >>> poly.fit_transform(X)\n",
      " |  array([[ 1.,  0.,  1.,  0.,  0.,  1.],\n",
      " |         [ 1.,  2.,  3.,  4.,  6.,  9.],\n",
      " |         [ 1.,  4.,  5., 16., 20., 25.]])\n",
      " |  >>> poly = PolynomialFeatures(interaction_only=True)\n",
      " |  >>> poly.fit_transform(X)\n",
      " |  array([[ 1.,  0.,  1.,  0.],\n",
      " |         [ 1.,  2.,  3.,  6.],\n",
      " |         [ 1.,  4.,  5., 20.]])\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      PolynomialFeatures\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      sklearn.utils._set_output._SetOutputMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(\n",
      " |      self,\n",
      " |      degree=2,\n",
      " |      *,\n",
      " |      interaction_only=False,\n",
      " |      include_bias=True,\n",
      " |      order='C'\n",
      " |  )\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  __sklearn_tags__(self)\n",
      " |\n",
      " |  fit(self, X, y=None)\n",
      " |      Compute number of output features.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The data.\n",
      " |\n",
      " |      y : Ignored\n",
      " |          Not used, present here for API consistency by convention.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted transformer.\n",
      " |\n",
      " |  get_feature_names_out(self, input_features=None)\n",
      " |      Get output feature names for transformation.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      input_features : array-like of str or None, default=None\n",
      " |          Input features.\n",
      " |\n",
      " |          - If `input_features is None`, then `feature_names_in_` is\n",
      " |            used as feature names in. If `feature_names_in_` is not defined,\n",
      " |            then the following input feature names are generated:\n",
      " |            `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n",
      " |          - If `input_features` is an array-like, then `input_features` must\n",
      " |            match `feature_names_in_` if `feature_names_in_` is defined.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_names_out : ndarray of str objects\n",
      " |          Transformed feature names.\n",
      " |\n",
      " |  transform(self, X)\n",
      " |      Transform data to polynomial features.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The data to transform, row by row.\n",
      " |\n",
      " |          Prefer CSR over CSC for sparse input (for speed), but CSC is\n",
      " |          required if the degree is 4 or higher. If the degree is less than\n",
      " |          4 and the input format is CSC, it will be converted to CSR, have\n",
      " |          its polynomial features generated, then converted back to CSC.\n",
      " |\n",
      " |          If the degree is 2 or 3, the method described in \"Leveraging\n",
      " |          Sparsity to Speed Up Polynomial Feature Expansions of CSR Matrices\n",
      " |          Using K-Simplex Numbers\" by Andrew Nystrom and John Hughes is\n",
      " |          used, which is much faster than the method used on CSC input. For\n",
      " |          this reason, a CSC input will be converted to CSR, and the output\n",
      " |          will be converted back to CSC prior to being returned, hence the\n",
      " |          preference of CSR.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      XP : {ndarray, sparse matrix} of shape (n_samples, NP)\n",
      " |          The matrix of features, where `NP` is the number of polynomial\n",
      " |          features generated from the combination of inputs. If a sparse\n",
      " |          matrix is provided, it will be converted into a sparse\n",
      " |          `csr_matrix`.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |\n",
      " |  powers_\n",
      " |      Exponent for each of the inputs in the output.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |\n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |\n",
      " |      Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
      " |      and returns a transformed version of `X`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input samples.\n",
      " |\n",
      " |      y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n",
      " |          Target values (None for unsupervised transformations).\n",
      " |\n",
      " |      **fit_params : dict\n",
      " |          Additional fit parameters.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
      " |          Transformed array.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      " |\n",
      " |  set_output(self, *, transform=None)\n",
      " |      Set output container.\n",
      " |\n",
      " |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n",
      " |      for an example on how to use the API.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      transform : {\"default\", \"pandas\", \"polars\"}, default=None\n",
      " |          Configure output of `transform` and `fit_transform`.\n",
      " |\n",
      " |          - `\"default\"`: Default output format of a transformer\n",
      " |          - `\"pandas\"`: DataFrame output\n",
      " |          - `\"polars\"`: Polars output\n",
      " |          - `None`: Transform configuration is unchanged\n",
      " |\n",
      " |          .. versionadded:: 1.4\n",
      " |              `\"polars\"` option was added.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      " |\n",
      " |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs)\n",
      " |      Set the ``set_{method}_request`` methods.\n",
      " |\n",
      " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      " |      looks for the information available in the set default values which are\n",
      " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      " |      from method signatures.\n",
      " |\n",
      " |      The ``__metadata_request__*`` class attributes are used when a method\n",
      " |      does not explicitly accept a metadata through its arguments or if the\n",
      " |      developer would like to specify a request value for those metadata\n",
      " |      which are different from the default ``None``.\n",
      " |\n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |\n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |\n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |\n",
      " |  __setstate__(self, state)\n",
      " |\n",
      " |  __sklearn_clone__(self)\n",
      " |\n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |\n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |\n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |\n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |\n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(PolynomialFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36b1dc32-3586-46a2-b187-72026e71e734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " original x  [[0 1 2]\n",
      " [3 4 5]]\n",
      " == == == \n",
      "[[ 1.  0.  1.  2.  0.  0.  0.  1.  2.  4.]\n",
      " [ 1.  3.  4.  5.  9. 12. 15. 16. 20. 25.]]\n",
      "[[ 1.  0.  1.  2.  0.  0.  0.  1.  2.  4.]\n",
      " [ 1.  3.  4.  5.  9. 12. 15. 16. 20. 25.]]\n",
      " == == == \n",
      "[[  1.   0.   1.   2.   0.   0.   0.   1.   2.   4.   0.   0.   0.   0.\n",
      "    0.   0.   1.   2.   4.   8.]\n",
      " [  1.   3.   4.   5.   9.  12.  15.  16.  20.  25.  27.  36.  45.  48.\n",
      "   60.  75.  64.  80. 100. 125.]]\n",
      "[[  1.   0.   1.   2.   0.   0.   0.   1.   2.   4.   0.   0.   0.   0.\n",
      "    0.   0.   1.   2.   4.   8.]\n",
      " [  1.   3.   4.   5.   9.  12.  15.  16.  20.  25.  27.  36.  45.  48.\n",
      "   60.  75.  64.  80. 100. 125.]]\n",
      " == == == \n"
     ]
    }
   ],
   "source": [
    "X = np.arange(6).reshape(2, 3)\n",
    "print( ' original x ', X)\n",
    "print(\" == == == \")\n",
    "poly = PolynomialFeatures(2)\n",
    "v1 = poly.fit_transform(X)\n",
    "print(v1)\n",
    "v2 = poly.transform(X)\n",
    "print(v2)\n",
    "print(\" == == == \")\n",
    "poly = PolynomialFeatures(3)\n",
    "v1 = poly.fit_transform(X)\n",
    "print(v1)\n",
    "v2 = poly.transform(X)\n",
    "print(v2)\n",
    "print(\" == == == \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2da0b71-b5e3-499d-8f59-982379bae2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
