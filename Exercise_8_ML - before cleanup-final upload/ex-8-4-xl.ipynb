{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Principal Components and Original Features\n",
    "\n",
    "This notebook compares the performance of regression models built on two different datasets:\n",
    "1. A dataset with pre-computed Principal Components (`sheet 1.csv`).\n",
    "2. The original feature set from `curse-of-dimensionality.xlsx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Define the regression models to be used in this analysis\n",
    "algorithms = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'SVR': SVR(),\n",
    "    'RandomForest': RandomForestRegressor(random_state=42),\n",
    "    'GradientBoosting': GradientBoostingRegressor(random_state=42),\n",
    "    'KNN': KNeighborsRegressor(),\n",
    "    'MLP': MLPRegressor(random_state=42, max_iter=1000)\n",
    "}\n",
    "\n",
    "# List to store all metrics data before creating the final DataFrame\n",
    "all_metrics_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Analysis with Principal Components from `sheet 1.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed metrics for 2-PC and 4-PC cases from CSV.\n"
     ]
    }
   ],
   "source": [
    "# 1. Read \"sheet 1.csv\" into a dataframe.\n",
    "try:\n",
    "    df_csv = pd.read_csv(\"sheet 1.csv\")\n",
    "\n",
    "    # 2. Prepare feature matrix (X) and target vector (y)\n",
    "    X_csv = df_csv[['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8']]\n",
    "    y_csv = df_csv['y']\n",
    "\n",
    "    # --- 3. Create models using first 2 PCs ---\n",
    "    X_2_pcs = X_csv[['PC1', 'PC2']]\n",
    "    X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2_pcs, y_csv, test_size=0.2, random_state=42)\n",
    "\n",
    "    for name, model in algorithms.items():\n",
    "        model.fit(X_train_2, y_train_2)\n",
    "        y_pred = model.predict(X_test_2)\n",
    "        r2 = r2_score(y_test_2, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test_2, y_pred))\n",
    "        all_metrics_data.append({\n",
    "            'Algorithm': name,\n",
    "            'Case': '2 Principal Components',\n",
    "            'R2 Score': r2,\n",
    "            'RMSE': rmse\n",
    "        })\n",
    "\n",
    "    # --- 4. Create models using first 4 PCs ---\n",
    "    X_4_pcs = X_csv[['PC1', 'PC2', 'PC3', 'PC4']]\n",
    "    X_train_4, X_test_4, y_train_4, y_test_4 = train_test_split(X_4_pcs, y_csv, test_size=0.2, random_state=42)\n",
    "\n",
    "    for name, model in algorithms.items():\n",
    "        model.fit(X_train_4, y_train_4)\n",
    "        y_pred = model.predict(X_test_4)\n",
    "        r2 = r2_score(y_test_4, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test_4, y_pred))\n",
    "        all_metrics_data.append({\n",
    "            'Algorithm': name,\n",
    "            'Case': '4 Principal Components',\n",
    "            'R2 Score': r2,\n",
    "            'RMSE': rmse\n",
    "        })\n",
    "    \n",
    "    print(\"Processed metrics for 2-PC and 4-PC cases from CSV.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'sheet 1.csv' not found. Please make sure the file is in the correct directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Analysis with Original Features from `curse-of-dimensionality.xlsx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed metrics for Original Features case from Excel.\n"
     ]
    }
   ],
   "source": [
    "# 5. Read \"Sheet3\" data from \"curse-of-dimensionality.xlsx\"\n",
    "try:\n",
    "    df_excel = pd.read_excel(\"curse-of-dimensionality.xlsx\", sheet_name=\"Sheet3\")\n",
    "    df_excel_cleaned = df_excel.dropna()\n",
    "\n",
    "    # 6. Identify columns based on headers\n",
    "    y_excel = df_excel_cleaned['y']\n",
    "    X_excel = df_excel_cleaned[['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8']]\n",
    "\n",
    "    # 7. Create same ML regression models\n",
    "    X_train_excel, X_test_excel, y_train_excel, y_test_excel = train_test_split(X_excel, y_excel, test_size=0.2, random_state=42)\n",
    "\n",
    "    for name, model in algorithms.items():\n",
    "        model.fit(X_train_excel, y_train_excel)\n",
    "        y_pred = model.predict(X_test_excel)\n",
    "        r2 = r2_score(y_test_excel, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test_excel, y_pred))\n",
    "        all_metrics_data.append({\n",
    "            'Algorithm': name,\n",
    "            'Case': 'Original Features',\n",
    "            'R2 Score': r2,\n",
    "            'RMSE': rmse\n",
    "        })\n",
    "\n",
    "    print(\"Processed metrics for Original Features case from Excel.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'curse-of-dimensionality.xlsx' not found. Please make sure the file is in the correct directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Consolidated Model Performance Report ---\n",
      "Case              2 Principal Components           4 Principal Components  \\\n",
      "                                R2 Score      RMSE               R2 Score   \n",
      "Algorithm                                                                   \n",
      "GradientBoosting                0.831953  0.393178               0.852496   \n",
      "KNN                             0.862759  0.355317               0.862759   \n",
      "Linear Regression               0.854173  0.366263               0.880922   \n",
      "MLP                             0.860280  0.358512               0.865046   \n",
      "RandomForest                    0.840930  0.382533               0.868168   \n",
      "SVR                             0.869939  0.345898               0.868629   \n",
      "\n",
      "Case                        Original Features            \n",
      "                       RMSE          R2 Score      RMSE  \n",
      "Algorithm                                                \n",
      "GradientBoosting   0.368362          0.858391  0.360926  \n",
      "KNN                0.355317          0.864742  0.352740  \n",
      "Linear Regression  0.330971          0.637927  0.577127  \n",
      "MLP                0.352344          0.871741  0.343493  \n",
      "RandomForest       0.348245          0.850685  0.370617  \n",
      "SVR                0.347635          0.883796  0.326952  \n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame from the collected data\n",
    "results_df = pd.DataFrame(all_metrics_data)\n",
    "\n",
    "# Pivot the DataFrame to get the desired structure for the report\n",
    "final_report = results_df.pivot_table(\n",
    "    index='Algorithm',\n",
    "    columns='Case',\n",
    "    values=['R2 Score', 'RMSE']\n",
    ")\n",
    "\n",
    "# Reorder the columns for better readability\n",
    "final_report = final_report.reorder_levels([1, 0], axis=1)\n",
    "column_order = [\n",
    "    '2 Principal Components',\n",
    "    '4 Principal Components',\n",
    "    'Original Features'\n",
    "]\n",
    "final_report = final_report.reindex(columns=column_order, level=0)\n",
    "\n",
    "print(\"--- Consolidated Model Performance Report ---\")\n",
    "print(final_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
